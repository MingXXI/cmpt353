{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from math import sqrt\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(directory_name , fileName):\n",
    "    '''\n",
    "    Read the file from a directory given directory name and file name, we collected all the data in one directory \n",
    "    '''\n",
    "    read_file = 'sensor data/' + directory_name + '/' + fileName + '.csv'\n",
    "    df = pd.read_csv(read_file)                                           # Create a DataFrame for return value \n",
    "    del df['Unnamed: 7']                                                  # delete unknown columns to make DataFrame clean  \n",
    "    df = df[ (df['time'] >= 3) & (df['time'] <= 6) ]                      # Only included time from 5s to 15s\n",
    "    df['aT'] = np.sqrt(df['ax']**2 + df['ay']**2 + df['az']**2)           # get total acceleration\n",
    "    return df                                                             # return the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_csv('sensor data' , '上楼梯口袋1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Butterworth_filter(data):\n",
    "    '''\n",
    "    Low-pass: keep the low frequencies; discard the high.\n",
    "    High-pass: keep the high frequencies; discard the low.\n",
    "    '''\n",
    "    b, a = signal.butter(3, 0.05, btype = 'lowpass', analog = False)\n",
    "    low_passed = signal.filtfilt(b, a, data)\n",
    "    return low_passed\n",
    "\n",
    "\n",
    "def Butterworth_filter_forplot(data):\n",
    "    '''\n",
    "    Given a dataFrame , apply Butterworth filter for each column \n",
    "    '''\n",
    "    data = data.apply(Butterworth_filter , axis = 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation: https://github.com/philip-L/CMPT353-1/blob/master/analysis2.py\n",
    "# Figure out what happening here, write our own FFT function and report must mention why we do this \n",
    "def Butterworth_filter_and_FFT(data):\n",
    "    # Using the Butterworth filter\n",
    "    data_bw = data.apply(Butterworth_filter , axis = 0)\n",
    "    data_bw = data_bw.reset_index(drop = True)\n",
    "    # del data_bw['time']\n",
    "    data = data.reset_index(drop = True)\n",
    "    # FFT of the data after the Butterworth filter\n",
    "    data_FT = data_bw.apply(np.fft.fft , axis = 0)      \n",
    "    data_FT = data_FT.apply(np.fft.fftshift , axis = 0)\n",
    "    data_FT = data_FT.abs()\n",
    "    \n",
    "    # Determine the sampling frequency\n",
    "    Fs = round(len(data) / data.at[len(data)-1, 'time']) #samples per second\n",
    "    data_FT['freq'] = np.linspace(-Fs/2, Fs/2, num = len(data))\n",
    "    \n",
    "    # Find the largest peak at a frequency greater than 0 to determine the average steps per second\n",
    "    temp_FT = data_FT[data_FT['freq'] > 0.1]\n",
    "    ind = temp_FT['aT'].nlargest(n = 1)\n",
    "    max_ind = ind.idxmax()\n",
    "    avg_freq = data_FT.at[max_ind , 'freq']\n",
    "    \n",
    "    #Transform the data to fit a normal distribution\n",
    "    max_val = data_FT['aT'].nlargest(n = 1)\n",
    "    max_val_ind = max_val.idxmax()\n",
    "    data_FT.at[max_val_ind , 'aT'] = temp_FT['aT'].max()\n",
    "    \n",
    "    return data_FT , avg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Butterworth_filter_and_FFT(read_csv('walk_hold' , 'walk_hold2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acceleration_FFT(data_FT):\n",
    "    plt.figure(figsize = (20, 15))\n",
    "    plt.plot(data_FT['freq'] , data_FT['aT'] , 'r-' , alpha = 0.5)\n",
    "    plt.title(\"FFT for total acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Butterworth_filter_and_FFT(read_csv('walk_hold' , 'walk_hold2'))\n",
    "#plot_acceleration_FFT(Butterworth_filter_and_FFT(read_csv('walk_hold' , 'walk_hold2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acceleration(data):\n",
    "    '''\n",
    "    General function for plot the accleration. Subplot 4 graph, x axis y axis z axis and total accleration\n",
    "    '''\n",
    "    plt.figure(figsize = (30, 30))\n",
    "    plt.subplot(4 , 1 , 1)\n",
    "    plt.plot(data['time'] , data['ax'] , 'r.' , alpha = 0.5)\n",
    "    plt.title('X axis acceleration')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Acceleration(m/s^2)')\n",
    "    plt.subplot(4 , 1 , 2)\n",
    "    plt.plot(data['time'] , data['ay'] , 'g.' , alpha = 0.5)\n",
    "    plt.title('Y axis acceleration')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Acceleration(m/s^2)')\n",
    "    plt.subplot(4 , 1 , 3)\n",
    "    plt.plot(data['time'] , data['az'] , 'b.' , alpha = 0.5)\n",
    "    plt.title('Z axis acceleration')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Acceleration(m/s^2)')\n",
    "    plt.subplot(4 , 1 , 4)\n",
    "    plt.plot(data['time'] , data['aT'] , 'k.' , alpha = 0.5)\n",
    "    plt.title('Total acceleration')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Acceleration(m/s^2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_acceleration(Butterworth_filter_forplot(read_csv('falldown_hold' , 'falldown_hold1')))\n",
    "#plot_acceleration(read_csv('falldown_hold' , 'falldown_hold1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_acceleration(Butterworth_filter_forplot(read_csv('sensor data' , '上楼梯手持8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_gyroscope(data):\n",
    "    '''\n",
    "    General function for plot the Gyroscope. Subplot 3 graph, x axis y axis z axis\n",
    "    '''\n",
    "    plt.figure(figsize = (30, 30))\n",
    "    plt.subplot(3 , 1 , 1)\n",
    "    plt.plot(data['time'] , data['wx'] , 'r.' , alpha = 0.5)\n",
    "    plt.title('X axis gyroscope')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Gyroscope(rad/s)')\n",
    "    plt.subplot(3 , 1 , 2)\n",
    "    plt.plot(data['time'] , data['wy'] , 'g.' , alpha = 0.5)\n",
    "    plt.title('Y axis gyroscope')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Gyroscope(rad/s)')\n",
    "    plt.subplot(3 , 1 , 3)\n",
    "    plt.plot(data['time'] , data['wz'] , 'b.' , alpha = 0.5)\n",
    "    plt.title('Z axis gyroscope')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Gyroscope(rad/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_gyroscope(Butterworth_filter_forplot(read_csv('sensor data' , '摔倒手持4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_basic_feature(data):\n",
    "    # The parameter will be the original dataFrame after some data cleaning\n",
    "    '''\n",
    "    ax , ay , az , wx , wy , wz , aT\n",
    "    mean        0.379203\n",
    "    std         2.659466\n",
    "    min       -11.236750\n",
    "    25%        -0.963552\n",
    "    50%         0.422153\n",
    "    75%         1.849594\n",
    "    max         9.068970\n",
    "    Get the basic statistical feature for each direction of acceleration and gyrpscope\n",
    "    .describe will give us mean, std, min, 25%, 50%, 75%, max value. All of these are basic feature we need give it to Machine Learning\n",
    "    '''\n",
    "    stat_summary = []\n",
    "    ax_stat_summary = data['ax'].describe()      # .describe get the basic feature \n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(ax_stat_summary[i])  # each feature append it to the list  \n",
    "    ay_stat_summary = data['ay'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(ay_stat_summary[i])\n",
    "    az_stat_summary = data['az'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(az_stat_summary[i]) \n",
    "    wx_stat_summary = data['wx'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(wx_stat_summary[i]) \n",
    "    wy_stat_summary = data['wy'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(wy_stat_summary[i]) \n",
    "    wz_stat_summary = data['wz'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(wz_stat_summary[i]) \n",
    "    aT_stat_summary = data['aT'].describe()\n",
    "    for i in range(1 , 8):\n",
    "        stat_summary.append(aT_stat_summary[i]) \n",
    "\n",
    "    return stat_summary # return a large list that given a dataFrame, return all the basic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_basic_feature(Butterworth_filter_forplot(read_csv('sensor data' , '上楼梯口袋1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_slope_max(data_col):\n",
    "    data_shift = data_col.shift(periods = -1 , fill_value = 0)\n",
    "    data_difference = abs(data_col - data_shift) \n",
    "    data_slope = abs(data_difference / data_col)\n",
    "    data_slope = data_slope[:-1]\n",
    "    return data_slope.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_acceleration_slope_max(Butterworth_filter_forplot(read_csv('sensor data' , '走路口袋10'))['aT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_feature_butterworth(data):\n",
    "    data_bw = Butterworth_filter_forplot(data)\n",
    "    data_feature = get_basic_feature(data_bw)\n",
    "    '''\n",
    "    ax_slope_max = get_acceleration_slope_max(data['ax'])\n",
    "    ay_slope_max = get_acceleration_slope_max(data['ay'])\n",
    "    az_slope_max = get_acceleration_slope_max(data['az'])\n",
    "    wx_slope_max = get_acceleration_slope_max(data['wx'])\n",
    "    wy_slope_max = get_acceleration_slope_max(data['wy'])\n",
    "    wz_slope_max = get_acceleration_slope_max(data['wz'])\n",
    "    aT_slope_max = get_acceleration_slope_max(data['aT'])\n",
    "\n",
    "    data_feature.append(ax_slope_max)\n",
    "    data_feature.append(ay_slope_max)\n",
    "    data_feature.append(az_slope_max)\n",
    "    data_feature.append(wx_slope_max)\n",
    "    data_feature.append(wy_slope_max)\n",
    "    data_feature.append(wz_slope_max)\n",
    "    data_feature.append(aT_slope_max)\n",
    "    '''\n",
    "    return data_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dataFrame():\n",
    "    feature_list = []\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('downstairs_hold' , 'downstairs_hold' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('downstairs_hold')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('downstairs_inpocket' , 'downstairs_inpocket' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('downstairs_inpocket')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('upstairs_inpocket' , 'upstairs_inpocket' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('unstairs_inpocket')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('upstairs_hold' , 'upstairs_hold' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('upstairs_hold')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('walk_hold' , 'walk_hold' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('walk_hold')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('walk_inpocket' , 'walk_inpocket' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('walk_inpocket')\n",
    "        feature_list.append(data_feature)\n",
    "\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('falldown_hold' , 'falldown_hold' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('falldown_hold')\n",
    "        feature_list.append(data_feature)  \n",
    "        \n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('falldown_inpocket' , 'falldown_inpocket' + str(i))\n",
    "        data_feature = get_basic_feature_butterworth(data)\n",
    "        data_avgFFT = Butterworth_filter_and_FFT(data)[1]\n",
    "        data_feature.append('falldown_inpocket')\n",
    "        feature_list.append(data_feature)  \n",
    "        \n",
    "\n",
    "    '''\n",
    "    ax , ay , az , wx , wy , wz , aT\n",
    "    mean        0.379203\n",
    "    std         2.659466\n",
    "    min       -11.236750\n",
    "    25%        -0.963552\n",
    "    50%         0.422153\n",
    "    75%         1.849594\n",
    "    max         9.068970\n",
    "    '''\n",
    "    '''\n",
    "    'ax_slope_max' , 'ay_slope_max' , 'az_slope_max' , 'wx_slope_max' , 'wy_slope_max' , \n",
    "                   'wz_slope_max' , 'aT_slope_max' , 'catogary'\n",
    "    '''\n",
    "    column_name = ['ax_mean' , 'ax_std' , 'ax_min' , 'ax_25' , 'ax_50' , 'ax_75' , 'ax_max',\n",
    "                   'ay_mean' , 'ay_std' , 'ay_min' , 'ay_25' , 'ay_50' , 'ay_75' , 'ay_max',\n",
    "                   'az_mean' , 'az_std' , 'az_min' , 'az_25' , 'az_50' , 'az_75' , 'az_max',\n",
    "                   'wx_mean' , 'wx_std' , 'wx_min' , 'wx_25' , 'wx_50' , 'wx_75' , 'wx_max',\n",
    "                   'wy_mean' , 'wy_std' , 'wy_min' , 'wy_25' , 'wy_50' , 'wy_75' , 'wy_max',\n",
    "                   'wz_mean' , 'wz_std' , 'wz_min' , 'wz_25' , 'wz_50' , 'wz_75' , 'wz_max',\n",
    "                   'aT_mean' , 'aT_std' , 'aT_min' , 'aT_25' , 'aT_50' , 'aT_75' , 'aT_max',\n",
    "                   'catogary']\n",
    "    df = pd.DataFrame(feature_list , columns = column_name)\n",
    "    df.to_csv('feature_df.csv' , index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X():\n",
    "    X = []\n",
    "    for i in range(1 , 16):\n",
    "        X.append(get_basic_feature_butterworth(read_csv('downstairs_hold' , 'downstairs_hold' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('downstairs_inpocket' , 'downstairs_inpocket' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('upstairs_hold' , 'upstairs_hold' + str(i))))      \n",
    "        X.append(get_basic_feature_butterworth(read_csv('upstairs_inpocket' , 'upstairs_inpocket' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('walk_hold' , 'walk_hold' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('walk_inpocket' , 'walk_inpocket' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('falldown_hold' , 'falldown_hold' + str(i))))\n",
    "        X.append(get_basic_feature_butterworth(read_csv('falldown_inpocket' , 'falldown_inpocket' + str(i))))\n",
    "    return X    \n",
    "\n",
    "def get_y():\n",
    "    y = []\n",
    "    for i in range(1, 16):\n",
    "        y.append('downstairs_hold')\n",
    "        y.append('downstairs_inpocket')\n",
    "        y.append('upstairs_hold')\n",
    "        y.append('upstairs_inpocket')\n",
    "        y.append('walk_hold')\n",
    "        y.append('walk_inpocket')\n",
    "        y.append('falldown_hold')\n",
    "        y.append('falldown_inpocket')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_feature_dataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_data(directory_name , fileName):\n",
    "    '''\n",
    "    Some time we don't just want the predict score, we want to know given an input data, what will the Machine Learning\n",
    "    exactly give us. So this piece of code is build the test data. Also we collect some test data. \n",
    "    '''\n",
    "    test_data = pd.read_csv(directory_name + '/' + fileName + '.csv')\n",
    "    \n",
    "    del test_data['Unnamed: 7']                                                             # Delete unknown columns to make DataFrame clean  \n",
    "    test_data = test_data[ (test_data['time'] >= 3) & (test_data['time'] <= 6) ]            # Only included time from 5s to 15s\n",
    "    test_data['aT'] = np.sqrt(test_data['ax']**2 + test_data['ay']**2 + test_data['az']**2) # Get total acceleration\n",
    "    feature_list = []\n",
    "    feature = get_basic_feature(test_data)\n",
    "    feature_list.append(feature)\n",
    "    column_name = ['ax_mean' , 'ax_std' , 'ax_min' , 'ax_25' , 'ax_50' , 'ax_75' , 'ax_max',\n",
    "               'ay_mean' , 'ay_std' , 'ay_min' , 'ay_25' , 'ay_50' , 'ay_75' , 'ay_max',\n",
    "               'az_mean' , 'az_std' , 'az_min' , 'az_25' , 'az_50' , 'az_75' , 'az_max',\n",
    "               'wx_mean' , 'wx_std' , 'wx_min' , 'wx_25' , 'wx_50' , 'wx_75' , 'wx_max',\n",
    "               'wy_mean' , 'wy_std' , 'wy_min' , 'wy_25' , 'wy_50' , 'wy_75' , 'wy_max',\n",
    "               'wz_mean' , 'wz_std' , 'wz_min' , 'wz_25' , 'wz_50' , 'wz_75' , 'wz_max',\n",
    "               'aT_mean' , 'aT_std' , 'aT_min' , 'aT_25' , 'aT_50' , 'aT_75' , 'aT_max',]\n",
    "               \n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_test_data('Test predict data' , 'downstairs_hold_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_normaltest():\n",
    "    for i in range(1 , 16):\n",
    "        data = read_csv('downstairs_hold' , 'downstairs_hold' + str(i))\n",
    "        data_FFT = Butterworth_filter_and_FFT(data)\n",
    "        data_FFT_pvalue = stats.normaltest(data_FFT['aT']).pvalue\n",
    "        if (data_FFT_pvalue <= 0.05):\n",
    "            print('downstairs_hold' + str(i) , \"is not normal\" , \"pvalue:\" , data_FFT_pvalue)\n",
    "        else:\n",
    "            print('downstairs_hold' + str(i) , \"is normal\" , \"pvalue:\" , data_FFT_pvalue)\n",
    "            \n",
    "        data = read_csv('upstairs_hold' , 'upstairs_hold' + str(i))\n",
    "        data_FFT = Butterworth_filter_and_FFT(data)\n",
    "        data_FFT_pvalue = stats.normaltest(data_FFT['aT']).pvalue\n",
    "        if (data_FFT_pvalue <= 0.05):\n",
    "            print('upstairs_hold' + str(i) , \"is not normal\" , \"pvalue:\" , data_FFT_pvalue)\n",
    "        else:\n",
    "            print('upstairs_hold' + str(i) , \"is normal\" , \"pvalue:\" , data_FFT_pvalue)\n",
    "            \n",
    "        data = read_csv('walk_hold' , 'walk_hold' + str(i))\n",
    "        data_FFT = Butterworth_filter_and_FFT(data)\n",
    "        data_FFT_pvalue = stats.normaltest(data_FFT['aT']).pvalue\n",
    "        if (data_FFT_pvalue <= 0.05):\n",
    "            print('walk_hold' + str(i) , \"is not normal\" , \"pvalue:\" , data_FFT_pvalue)\n",
    "        else:\n",
    "            print('walk_hold' + str(i) , \"is normal\" , \"pvalue:\" , data_FFT_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FFT_normaltest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
